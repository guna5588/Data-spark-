{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "  host = \"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "  port = 4000,\n",
    "  user = \"3odVFo6TfLUYgWX.root\",\n",
    "  password = \"k3MbqRTW3UQ601wG\"\n",
    "  \n",
    ")\n",
    "cloudcursor = connection.cursor(buffered=True)\n",
    "cloudcursor.execute(\"create database dataspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\guna\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\guna\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\guna\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\guna\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\guna\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\guna\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "customer = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/Customers.csv', encoding='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "customer = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/Customers.csv', encoding='latin1')\n",
    "# Ensure all rows and columns are displayed in the output\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Prevent line breaks\n",
    "pd.set_option('display.colheader_justify', 'center')  # Center-align headers\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "from IPython.display import display\n",
    "display(customer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CustomerKey\n",
      "count  1.526600e+04\n",
      "mean   1.060508e+06\n",
      "std    6.127097e+05\n",
      "min    3.010000e+02\n",
      "25%    5.140335e+05\n",
      "50%    1.079244e+06\n",
      "75%    1.593980e+06\n",
      "max    2.099937e+06\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15266 entries, 0 to 15265\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   CustomerKey  15266 non-null  int64 \n",
      " 1   Gender       15266 non-null  object\n",
      " 2   Name         15266 non-null  object\n",
      " 3   City         15266 non-null  object\n",
      " 4   State Code   15256 non-null  object\n",
      " 5   State        15266 non-null  object\n",
      " 6   Zip Code     15266 non-null  object\n",
      " 7   Country      15266 non-null  object\n",
      " 8   Continent    15266 non-null  object\n",
      " 9   Birthday     15266 non-null  object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15266, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(customer.describe())\n",
    "print(customer.info())\n",
    "customer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CustomerKey, Gender, Name, City, State Code, State, Zip Code, Country, Continent, Birthday]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Duplicate check in the whole data set\n",
    "\n",
    "duplicate_rows = customer[customer.duplicated(keep=False)]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerKey     0\n",
       "Gender          0\n",
       "Name            0\n",
       "City            0\n",
       "State Code     10\n",
       "State           0\n",
       "Zip Code        0\n",
       "Country         0\n",
       "Continent       0\n",
       "Birthday        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CustomerKey State Code   State Country\n",
      "5304       729681        NaN  Napoli   Italy\n",
      "5316       732289        NaN  Napoli   Italy\n",
      "5372       742042        NaN  Napoli   Italy\n",
      "5377       742886        NaN  Napoli   Italy\n",
      "5378       743343        NaN  Napoli   Italy\n",
      "5485       759705        NaN  Napoli   Italy\n",
      "5525       765589        NaN  Napoli   Italy\n",
      "5531       766410        NaN  Napoli   Italy\n",
      "5631       781667        NaN  Napoli   Italy\n",
      "5695       789177        NaN  Napoli   Italy\n"
     ]
    }
   ],
   "source": [
    "# To show 10 state code null records\n",
    "\n",
    "null_state_data = customer[customer['State Code'].isnull()]\n",
    "print(null_state_data[['CustomerKey','State Code','State', 'Country']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CustomerKey  Gender                Name               City State Code  \\\n",
      "5304       729681  Female    Rossana Padovesi            Polvica        NaN   \n",
      "5316       732289    Male        Indro Piccio          Varcaturo        NaN   \n",
      "5372       742042    Male     Amaranto Loggia          Casaferro        NaN   \n",
      "5377       742886  Female       Edmonda Capon           Terzigno        NaN   \n",
      "5378       743343  Female        Ambra Sagese  Pomigliano D'Arco        NaN   \n",
      "5485       759705    Male    Callisto Lo Duca            Casilli        NaN   \n",
      "5525       765589    Male  Michelino Lucchesi       Pompei Scavi        NaN   \n",
      "5531       766410    Male   Adelmio Beneventi             Licola        NaN   \n",
      "5631       781667  Female          Ilda Manna             Napoli        NaN   \n",
      "5695       789177    Male   Calogero Folliero      Mariglianella        NaN   \n",
      "\n",
      "       State Zip Code Country Continent    Birthday  \n",
      "5304  Napoli    80035   Italy    Europe   4/18/1981  \n",
      "5316  Napoli    80014   Italy    Europe   2/24/1949  \n",
      "5372  Napoli    80034   Italy    Europe   3/14/1936  \n",
      "5377  Napoli    80040   Italy    Europe    8/6/1963  \n",
      "5378  Napoli    80038   Italy    Europe    1/5/1961  \n",
      "5485  Napoli    80047   Italy    Europe   8/28/1976  \n",
      "5525  Napoli    80045   Italy    Europe  11/13/1947  \n",
      "5531  Napoli    80078   Italy    Europe   1/13/1940  \n",
      "5631  Napoli    80134   Italy    Europe    5/8/1977  \n",
      "5695  Napoli    80030   Italy    Europe    3/3/2000  \n"
     ]
    }
   ],
   "source": [
    "napoli_data = customer[customer['State'] == 'Napoli']\n",
    "print(napoli_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CustomerKey  Gender                Name               City State Code  \\\n",
      "5304       729681  Female    Rossana Padovesi            Polvica         NA   \n",
      "5316       732289    Male        Indro Piccio          Varcaturo         NA   \n",
      "5372       742042    Male     Amaranto Loggia          Casaferro         NA   \n",
      "5377       742886  Female       Edmonda Capon           Terzigno         NA   \n",
      "5378       743343  Female        Ambra Sagese  Pomigliano D'Arco         NA   \n",
      "5485       759705    Male    Callisto Lo Duca            Casilli         NA   \n",
      "5525       765589    Male  Michelino Lucchesi       Pompei Scavi         NA   \n",
      "5531       766410    Male   Adelmio Beneventi             Licola         NA   \n",
      "5631       781667  Female          Ilda Manna             Napoli         NA   \n",
      "5695       789177    Male   Calogero Folliero      Mariglianella         NA   \n",
      "\n",
      "       State Zip Code Country Continent    Birthday  \n",
      "5304  Napoli    80035   Italy    Europe   4/18/1981  \n",
      "5316  Napoli    80014   Italy    Europe   2/24/1949  \n",
      "5372  Napoli    80034   Italy    Europe   3/14/1936  \n",
      "5377  Napoli    80040   Italy    Europe    8/6/1963  \n",
      "5378  Napoli    80038   Italy    Europe    1/5/1961  \n",
      "5485  Napoli    80047   Italy    Europe   8/28/1976  \n",
      "5525  Napoli    80045   Italy    Europe  11/13/1947  \n",
      "5531  Napoli    80078   Italy    Europe   1/13/1940  \n",
      "5631  Napoli    80134   Italy    Europe    5/8/1977  \n",
      "5695  Napoli    80030   Italy    Europe    3/3/2000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "NA = customer[customer['State Code'] == 'NA']\n",
    "print(NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CustomerKey  Gender                Name               City State Code  \\\n",
      "5304       729681  Female    Rossana Padovesi            Polvica         NA   \n",
      "5316       732289    Male        Indro Piccio          Varcaturo         NA   \n",
      "5372       742042    Male     Amaranto Loggia          Casaferro         NA   \n",
      "5377       742886  Female       Edmonda Capon           Terzigno         NA   \n",
      "5378       743343  Female        Ambra Sagese  Pomigliano D'Arco         NA   \n",
      "5485       759705    Male    Callisto Lo Duca            Casilli         NA   \n",
      "5525       765589    Male  Michelino Lucchesi       Pompei Scavi         NA   \n",
      "5531       766410    Male   Adelmio Beneventi             Licola         NA   \n",
      "5631       781667  Female          Ilda Manna             Napoli         NA   \n",
      "5695       789177    Male   Calogero Folliero      Mariglianella         NA   \n",
      "\n",
      "       State Zip Code Country Continent    Birthday  \n",
      "5304  Napoli    80035   Italy    Europe   4/18/1981  \n",
      "5316  Napoli    80014   Italy    Europe   2/24/1949  \n",
      "5372  Napoli    80034   Italy    Europe   3/14/1936  \n",
      "5377  Napoli    80040   Italy    Europe    8/6/1963  \n",
      "5378  Napoli    80038   Italy    Europe    1/5/1961  \n",
      "5485  Napoli    80047   Italy    Europe   8/28/1976  \n",
      "5525  Napoli    80045   Italy    Europe  11/13/1947  \n",
      "5531  Napoli    80078   Italy    Europe   1/13/1940  \n",
      "5631  Napoli    80134   Italy    Europe    5/8/1977  \n",
      "5695  Napoli    80030   Italy    Europe    3/3/2000  \n",
      "Cleaned data saved to cleaned_customer.csv\n"
     ]
    }
   ],
   "source": [
    "# Clean the 'State' column\n",
    "customer['State'] = customer['State'].str.strip().str.title()\n",
    "\n",
    "# Define the mapping\n",
    "state_to_code = {\n",
    "    'Napoli': 'NA',\n",
    "    # Add other mappings\n",
    "}\n",
    "\n",
    "# Replace null 'State Code' with mapped abbreviations\n",
    "customer['State Code'] = customer.apply(\n",
    "    lambda row: state_to_code.get(row['State'], row['State Code']) if pd.isnull(row['State Code']) else row['State Code'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Confirm the changes\n",
    "print(customer.loc[customer['State'] == 'Napoli'])\n",
    "\n",
    "# Save the cleaned data to a CSV file\n",
    "output_path = 'cleaned_customer.csv'\n",
    "customer.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SA' 'WA' 'VIC' 'QLD' 'NT' 'NSW' 'TAS' 'ACT' 'BC' 'QC' 'ON' 'AB' 'NS'\n",
      " 'SK' 'NU' 'PE' 'MB' 'NL' 'YT' 'NB' 'BB' 'RP' 'BY' 'BW' 'NW' 'NI' 'ST'\n",
      " 'MV' 'SN' 'TH' 'BE' 'HE' 'SL' 'SH' 'HB' 'HH' 'RA' 'IL' 'GY' 'AL' 'AQ'\n",
      " 'CA' 'NP' 'GD' 'FC' 'PA' 'PC' 'LI' 'MP' 'PI' 'HN' 'AU' 'PL' 'LO' 'BN'\n",
      " 'CE' 'LN' 'MQ' 'BO' 'BR' 'CO' 'MY' 'RC' 'VI' 'FE' 'RM' 'AG' 'IM' 'MI'\n",
      " 'PR' 'BG' 'RG' 'PN' 'SV' 'LU' 'CN' 'TN' 'LE' 'PD' 'BI' 'CH' 'GE' 'TO'\n",
      " 'VV' 'CZ' 'AN' 'PG' 'LT' 'BL' 'TV' 'PV' 'MN' 'VA' 'PT' 'SI' 'MS' 'CT'\n",
      " 'BS' 'SS' 'RO' 'CR' 'FI' 'GR' 'IS' 'SO' 'VE' 'OR' 'ME' 'VR' 'CS' 'BZ'\n",
      " 'NO' 'AV' 'TA' 'VC' 'GO' 'MO' 'FR' 'FG' 'TE' 'BA' 'UD' 'AP' 'TP' 'RE'\n",
      " 'PO' 'NA' 'AT' 'SR' 'RI' 'TS' 'KR' 'MT' 'PZ' 'MC' 'VT' 'AR' 'AO' 'CB'\n",
      " 'LC' 'SP' 'RN' 'FO' 'TR' 'UT' 'NH' 'DR' 'ZH' 'FL' 'OV' 'ZE' 'Falkirk'\n",
      " 'Ceredigion' 'North East Lincolnshire' 'Aberdeenshire' 'York'\n",
      " 'Pembrokeshire' 'Leicester' 'Highland' 'Tendring' 'Horsham' 'Newport'\n",
      " 'Bristol' 'Newark and Sherwood' 'Argyllshire' 'Lincoln' 'Tamworth'\n",
      " 'Fylde' 'Lewes' 'Rhondda Cynon Taf' 'Bromsgrove' 'Ripon' 'Cornwall'\n",
      " 'South Lanarkshire' 'Shropshire' 'Perth and Kinross' 'Crawley'\n",
      " 'Staffordshire' 'Mendip' 'Forest Heath' 'Moray' 'Bracknell Forest'\n",
      " 'Anglesey' 'Bolsover' 'Calderdale' 'Ashford' 'Sussex' 'Darlington'\n",
      " 'East Devon' 'Monmouthshire' 'Gloucester' 'Mid Devon' 'Somerset'\n",
      " 'Hereford' 'Bath and North East Somerset' 'Bassetlaw' 'Christchurch'\n",
      " 'West Berkshire' 'Gwynedd' 'Suffolk' 'Tewkesbury' 'Colchester'\n",
      " 'Llandrindod Wells' 'Harrogate' 'Winchester' 'Angus' 'Derbyshire Dales'\n",
      " 'Dacorum' 'Suffolk Coastal' 'Wiltshire' 'Leeds' 'Kennet' 'Hampshire'\n",
      " 'Norfolk' 'Northumberland' 'Doncaster' 'Purbeck' 'Wyre Forest'\n",
      " 'Redcar & Cleveland' 'West Dorset' 'Ipswich' 'Powys' 'Midlothian' 'Fife'\n",
      " 'North Ayrshire' 'Carmarthenshire' 'Birmingham' 'South Oxfordshire'\n",
      " 'North Yorkshire' 'Cheshire West and Chester' 'Scottish Borders'\n",
      " 'Lichfield' 'Rushcliffe' 'Arun' 'Dumfriesshire' 'Wakefield'\n",
      " 'Denbighshire' 'Plymouth' 'St Edmundsbury' 'Edinburgh' 'Liverpool' 'Kent'\n",
      " 'Warwick' 'Gedling' 'Shetland' 'Flintshire' 'Gravesham'\n",
      " 'Central Bedfordshire' 'North Dorset' 'Lancaster' 'Breckland'\n",
      " 'East Riding of Yorkshire' 'Exeter' 'Vale of White Horse' 'Cherwell'\n",
      " 'South Holland' 'South Lakeland' 'Stroud' 'Orkney Islands' 'West Lindsey'\n",
      " 'Stratford-on-Avon' 'West Oxfordshire' 'Bedford' 'Rother' 'Isle of Man'\n",
      " 'Swindon' 'Charnwood' 'Waverley' 'Wolverhampton' 'Aylesbury Vale'\n",
      " 'Merton' 'Sevenoaks' 'Allerdale' 'Bolton' 'Selby' 'Berkshire' 'Copeland'\n",
      " 'Chelmsford' 'South Kesteven' 'Cheshire East' 'Boston' 'County Durham'\n",
      " 'Mid Suffolk' 'Wandsworth' 'West Dunbartonshire' 'Erewash' 'Babergh'\n",
      " 'South Hams' 'Wigan' 'South Ayrshire' 'Rotherham' 'Isle of Wight'\n",
      " 'Cotswold' 'Worcester' 'Rutland' 'East Northamptonshire' 'Rugby'\n",
      " 'Stirling' 'North Kesteven' 'Comhairle nan Eilean Siar' 'Walsall'\n",
      " 'Knowsley' 'South Somerset' 'North Lincolnshire' 'South Norfolk'\n",
      " 'Aberdeen' 'Welwyn Hatfield' 'Kirkcudbrightshire' 'Carlisle' 'Hillingdon'\n",
      " 'West Norfolk' 'Kirklees' 'New Forest' 'Swansea' 'Craven' 'Camden'\n",
      " 'North Somerset' 'Teignbridge' 'Melton' 'Conwy' 'Enfield' 'Glasgow'\n",
      " 'Braintree' 'Chichester' 'North Hertfordshire' 'East Lothian'\n",
      " 'Renfrewshire' 'Eden' 'Uttlesford' 'Mid Sussex' 'Peterborough' 'Ashfield'\n",
      " 'Redbridge' 'Sheffield' 'Newcastle' 'Harlow' 'East Hampshire'\n",
      " 'Caerphilly' 'North Warwickshire' 'Brentwood' 'Tameside'\n",
      " 'Brighton and Hove' 'Rossendale' 'Swale' 'Sutton' 'Huntingdonshire'\n",
      " 'St Albans' 'Dudley' 'East Hertfordshire' 'Guildford' 'Cambridge'\n",
      " 'Woking' 'Daventry' 'Vale of Glamorgan' 'East Ayrshire' 'Bradford'\n",
      " 'South Buckinghamshire' 'Merthyr Tydfil' 'West Lothian' 'East Lindsey'\n",
      " 'Hambleton' 'Tower Hamlets' 'Test Valley' 'Dartford' 'Sunderland'\n",
      " 'Medway' 'Rochdale' 'Bury' 'Oxford' 'Bridgend' 'South Derbyshire'\n",
      " 'Milton Keynes' 'Southampton' 'Wokingham' 'Nottingham' 'Stevenage'\n",
      " 'Wirral' 'Dundee' 'Amber Valley' 'Harrow' 'East Dorset' 'Maidstone'\n",
      " 'Wigtownshire' 'Gateshead' 'Telford and Wrekin' 'Wellingborough'\n",
      " 'Runnymede' 'Wrexham' 'Cannock Chase' 'Kensington and Chelsea'\n",
      " 'South Gloucestershire' 'Wycombe' 'South Staffordshire' 'Sandwell'\n",
      " 'Bromley' 'Torridge' 'Burnley' 'Sefton' 'Ribble Valley' 'Chiltern'\n",
      " 'Hastings' 'East Staffordshire' 'Barnet' 'Reigate and Banstead'\n",
      " 'Basildon' 'Tandridge' 'Westminster' 'Warrington' 'West Lancashire'\n",
      " 'Preston' 'Canterbury' 'Wealden' 'Havering' 'West Devon' 'Islington'\n",
      " 'Wyre' 'Kinross-Shire' 'Waveney' 'North Lanarkshire' 'Ely'\n",
      " 'Neath Port Talbot' 'Nuneaton & Bedworth' 'Chesterfield' 'Mole Valley'\n",
      " 'South Northamptonshire' 'Broxbourne' 'Cardiff' 'Hackney' 'Redditch'\n",
      " 'Tunbridge Wells' 'Haringey' 'Malvern Hills' 'Broxtowe' 'Spelthorne'\n",
      " 'Coventry' 'Newmarket' 'Lanarkshire' 'East Dunbartonshire'\n",
      " 'Stockton-on-Tees' 'NC' 'MD' 'HI' 'NY' 'TX' 'GA' 'DE' 'WI' 'KS' 'NV' 'MA'\n",
      " 'NJ' 'OH' 'IA' 'KY' 'DC' 'OK' 'ID' 'AZ' 'IN' 'WV' 'NE' 'LA' 'AK' 'ND'\n",
      " 'SC' 'NM' 'SD' 'WY']\n"
     ]
    }
   ],
   "source": [
    "print(customer['State Code'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ft2=pd.read_csv(\"f:/project2/cleaned_Customer.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CustomerKey  Gender                Name               City State Code  \\\n",
      "5304       729681  Female    Rossana Padovesi            Polvica         NA   \n",
      "5316       732289    Male        Indro Piccio          Varcaturo         NA   \n",
      "5372       742042    Male     Amaranto Loggia          Casaferro         NA   \n",
      "5377       742886  Female       Edmonda Capon           Terzigno         NA   \n",
      "5378       743343  Female        Ambra Sagese  Pomigliano D'Arco         NA   \n",
      "5485       759705    Male    Callisto Lo Duca            Casilli         NA   \n",
      "5525       765589    Male  Michelino Lucchesi       Pompei Scavi         NA   \n",
      "5531       766410    Male   Adelmio Beneventi             Licola         NA   \n",
      "5631       781667  Female          Ilda Manna             Napoli         NA   \n",
      "5695       789177    Male   Calogero Folliero      Mariglianella         NA   \n",
      "\n",
      "       State Zip Code Country Continent    Birthday  \n",
      "5304  Napoli    80035   Italy    Europe   4/18/1981  \n",
      "5316  Napoli    80014   Italy    Europe   2/24/1949  \n",
      "5372  Napoli    80034   Italy    Europe   3/14/1936  \n",
      "5377  Napoli    80040   Italy    Europe    8/6/1963  \n",
      "5378  Napoli    80038   Italy    Europe    1/5/1961  \n",
      "5485  Napoli    80047   Italy    Europe   8/28/1976  \n",
      "5525  Napoli    80045   Italy    Europe  11/13/1947  \n",
      "5531  Napoli    80078   Italy    Europe   1/13/1940  \n",
      "5631  Napoli    80134   Italy    Europe    5/8/1977  \n",
      "5695  Napoli    80030   Italy    Europe    3/3/2000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(customer.loc[customer['State'] == 'Napoli'])  # Confirm changes for Napoli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerKey     0\n",
       "Gender          0\n",
       "Name            0\n",
       "City            0\n",
       "State Code     10\n",
       "State           0\n",
       "Zip Code        0\n",
       "Country         0\n",
       "Continent       0\n",
       "Birthday        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QLD</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NT</td>\n",
       "      <td>Northern Territory</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NSW</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TAS</td>\n",
       "      <td>Tasmania</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ACT</td>\n",
       "      <td>Australian Capital Territory</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>BC</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>QC</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>ON</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>AB</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>NS</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>SK</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>NU</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>PE</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>MB</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>NL</td>\n",
       "      <td>Newfoundland And Labrador</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>YT</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>NT</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>NB</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>BB</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>RP</td>\n",
       "      <td>Rheinland-Pfalz</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>BY</td>\n",
       "      <td>Freistaat Bayern</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>BW</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>NW</td>\n",
       "      <td>Nordrhein-Westfalen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>NI</td>\n",
       "      <td>Niedersachsen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>ST</td>\n",
       "      <td>Sachsen-Anhalt</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>MV</td>\n",
       "      <td>Mecklenburg-Vorpommern</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>SN</td>\n",
       "      <td>Freistaat Sachsen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>TH</td>\n",
       "      <td>Freistaat Thüringen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>BE</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>HE</td>\n",
       "      <td>Hessen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>SL</td>\n",
       "      <td>Saarland</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>SH</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>HB</td>\n",
       "      <td>Freie Hansestadt Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>HH</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>RA</td>\n",
       "      <td>Rhône-Alpes</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>IL</td>\n",
       "      <td>Île-De-France</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>GY</td>\n",
       "      <td>Guyane</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>AQ</td>\n",
       "      <td>Aquitaine</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>CA</td>\n",
       "      <td>Champagne-Ardenne</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>NP</td>\n",
       "      <td>Nord-Pas-De-Calais</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>GD</td>\n",
       "      <td>Guadeloupe</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>FC</td>\n",
       "      <td>Franche-Comté</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>PA</td>\n",
       "      <td>Provence-Alpes-Côte D'Azur</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>PC</td>\n",
       "      <td>Poitou-Charentes</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>LI</td>\n",
       "      <td>Limousin</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>MP</td>\n",
       "      <td>Midi-Pyrénées</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State Code                         State    Country\n",
       "0            SA               South Australia  Australia\n",
       "1            WA             Western Australia  Australia\n",
       "2           VIC                      Victoria  Australia\n",
       "6           QLD                    Queensland  Australia\n",
       "8            NT            Northern Territory  Australia\n",
       "12          NSW               New South Wales  Australia\n",
       "26          TAS                      Tasmania  Australia\n",
       "69          ACT  Australian Capital Territory  Australia\n",
       "1420         BC              British Columbia     Canada\n",
       "1421         QC                        Quebec     Canada\n",
       "1430         ON                       Ontario     Canada\n",
       "1434         AB                       Alberta     Canada\n",
       "1451         NS                   Nova Scotia     Canada\n",
       "1452         SK                  Saskatchewan     Canada\n",
       "1465         NU                       Nunavut     Canada\n",
       "1473         PE          Prince Edward Island     Canada\n",
       "1510         MB                      Manitoba     Canada\n",
       "1529         NL     Newfoundland And Labrador     Canada\n",
       "1556         YT                         Yukon     Canada\n",
       "1798         NT         Northwest Territories     Canada\n",
       "2286         NB                 New Brunswick     Canada\n",
       "2973         BB                   Brandenburg    Germany\n",
       "2974         RP               Rheinland-Pfalz    Germany\n",
       "2975         BY              Freistaat Bayern    Germany\n",
       "2976         BW             Baden-Württemberg    Germany\n",
       "2979         NW           Nordrhein-Westfalen    Germany\n",
       "2986         NI                 Niedersachsen    Germany\n",
       "2990         ST                Sachsen-Anhalt    Germany\n",
       "2992         MV        Mecklenburg-Vorpommern    Germany\n",
       "2997         SN             Freistaat Sachsen    Germany\n",
       "3002         TH           Freistaat Thüringen    Germany\n",
       "3008         BE                        Berlin    Germany\n",
       "3013         HE                        Hessen    Germany\n",
       "3024         SL                      Saarland    Germany\n",
       "3035         SH            Schleswig-Holstein    Germany\n",
       "3047         HB       Freie Hansestadt Bremen    Germany\n",
       "3051         HH                       Hamburg    Germany\n",
       "4446         RA                   Rhône-Alpes     France\n",
       "4447         IL                 Île-De-France     France\n",
       "4448         GY                        Guyane     France\n",
       "4449         AL                        Alsace     France\n",
       "4450         AQ                     Aquitaine     France\n",
       "4451         CA             Champagne-Ardenne     France\n",
       "4454         NP            Nord-Pas-De-Calais     France\n",
       "4455         GD                    Guadeloupe     France\n",
       "4457         FC                 Franche-Comté     France\n",
       "4459         PA    Provence-Alpes-Côte D'Azur     France\n",
       "4460         PC              Poitou-Charentes     France\n",
       "4465         LI                      Limousin     France\n",
       "4470         MP                 Midi-Pyrénées     France"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distinct state code ,state , coutry head of 50 records\n",
    "\n",
    "customer[['State Code', 'State', 'Country']].drop_duplicates().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerKey</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>Female</td>\n",
       "      <td>Lilly Harding</td>\n",
       "      <td>WANDEARAH EAST</td>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>5523</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1939-07-03</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325</td>\n",
       "      <td>Female</td>\n",
       "      <td>Madison Hull</td>\n",
       "      <td>MOUNT BUDD</td>\n",
       "      <td>WA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>6522</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1979-09-27</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>554</td>\n",
       "      <td>Female</td>\n",
       "      <td>Claire Ferres</td>\n",
       "      <td>WINJALLOK</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>3380</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1947-05-26</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>786</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jai Poltpalingada</td>\n",
       "      <td>MIDDLE RIVER</td>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>5223</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1957-09-17</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1042</td>\n",
       "      <td>Male</td>\n",
       "      <td>Aidan Pankhurst</td>\n",
       "      <td>TAWONGA SOUTH</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>3698</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1965-11-19</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1086</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hayden Clegg</td>\n",
       "      <td>TEMPLERS</td>\n",
       "      <td>SA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>5371</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1954-01-20</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1133</td>\n",
       "      <td>Male</td>\n",
       "      <td>Nicholas Caffyn</td>\n",
       "      <td>JUBILEE POCKET</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>4802</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1969-11-22</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1256</td>\n",
       "      <td>Male</td>\n",
       "      <td>Lincoln Jenks</td>\n",
       "      <td>KULLOGUM</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>4660</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1950-03-12</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1314</td>\n",
       "      <td>Male</td>\n",
       "      <td>Isaac Israel</td>\n",
       "      <td>EDITH RIVER</td>\n",
       "      <td>NT</td>\n",
       "      <td>Northern Territory</td>\n",
       "      <td>852</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1965-12-21</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1568</td>\n",
       "      <td>Male</td>\n",
       "      <td>Luke Virtue</td>\n",
       "      <td>KOTTA</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>3565</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1975-07-25</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerKey  Gender               Name            City State Code  \\\n",
       "0          301  Female      Lilly Harding  WANDEARAH EAST         SA   \n",
       "1          325  Female       Madison Hull      MOUNT BUDD         WA   \n",
       "2          554  Female      Claire Ferres       WINJALLOK        VIC   \n",
       "3          786    Male  Jai Poltpalingada    MIDDLE RIVER         SA   \n",
       "4         1042    Male    Aidan Pankhurst   TAWONGA SOUTH        VIC   \n",
       "5         1086    Male       Hayden Clegg        TEMPLERS         SA   \n",
       "6         1133    Male    Nicholas Caffyn  JUBILEE POCKET        QLD   \n",
       "7         1256    Male      Lincoln Jenks        KULLOGUM        QLD   \n",
       "8         1314    Male       Isaac Israel     EDITH RIVER         NT   \n",
       "9         1568    Male        Luke Virtue           KOTTA        VIC   \n",
       "\n",
       "                State Zip Code    Country  Continent   Birthday  Age  \n",
       "0     South Australia     5523  Australia  Australia 1939-07-03   85  \n",
       "1   Western Australia     6522  Australia  Australia 1979-09-27   45  \n",
       "2            Victoria     3380  Australia  Australia 1947-05-26   77  \n",
       "3     South Australia     5223  Australia  Australia 1957-09-17   67  \n",
       "4            Victoria     3698  Australia  Australia 1965-11-19   59  \n",
       "5     South Australia     5371  Australia  Australia 1954-01-20   70  \n",
       "6          Queensland     4802  Australia  Australia 1969-11-22   55  \n",
       "7          Queensland     4660  Australia  Australia 1950-03-12   74  \n",
       "8  Northern Territory      852  Australia  Australia 1965-12-21   58  \n",
       "9            Victoria     3565  Australia  Australia 1975-07-25   49  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert 'Birthday' column to datetime format if it's not already\n",
    "customer['Birthday'] = pd.to_datetime(customer['Birthday'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Assuming 'Birthday' column is in 'MM-DD-YYYY' format\n",
    "def calculate_age(birthdate):\n",
    "  # Check if birthdate is already a Timestamp object\n",
    "  if isinstance(birthdate, pd.Timestamp):\n",
    "    birthdate_obj = birthdate\n",
    "  else:\n",
    "    try:\n",
    "      birthdate_obj = datetime.strptime(birthdate, '%m-%d-%Y')\n",
    "    except ValueError:\n",
    "      return None\n",
    "  today = datetime.today()\n",
    "  age = today.year - birthdate_obj.year - ((today.month, today.day) < (birthdate_obj.month, birthdate_obj.day))\n",
    "  return age\n",
    "\n",
    "customer['Age'] = customer['Birthday'].apply(calculate_age)\n",
    "\n",
    "customer.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "  host = \"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "  port = 4000,\n",
    "  user = \"3odVFo6TfLUYgWX.root\",\n",
    "  password = \"k3MbqRTW3UQ601wG\",\n",
    "  database = \"dataspark\" \n",
    "  \n",
    ")\n",
    "cursor = connection.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully.\n",
      "MySQL connection is closed.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "# Define the SQL query\n",
    "\n",
    "# Create a connection\n",
    "try:\n",
    "    connection = mysql.connector.connect(\n",
    "  host = \"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "  port = 4000,\n",
    "  user = \"3odVFo6TfLUYgWX.root\",\n",
    "  password = \"k3MbqRTW3UQ601wG\",\n",
    "  database = \"dataspark\" \n",
    "  )\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "    create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS customer (\n",
    "    CustomerKey INT,\n",
    "    Gender VARCHAR(10),\n",
    "    Name VARCHAR(255),\n",
    "    City VARCHAR(255),\n",
    "    StateCode VARCHAR(200),\n",
    "    State VARCHAR(255),\n",
    "    ZipCode VARCHAR(20),\n",
    "    Country VARCHAR(255),\n",
    "    Continent VARCHAR(255),\n",
    "    Birthday DATE,\n",
    "    Age INT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "    # Commit the changes\n",
    "    connection.commit()\n",
    "    print(\"Table created successfully.\")\n",
    "    \n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15266 records inserted successfully in batches of 50.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Load the CSV file\n",
    "customer = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/Customers.csv', encoding='latin1')\n",
    "\n",
    "# Clean the 'State' column\n",
    "customer['State'] = customer['State'].str.strip().str.title()\n",
    "\n",
    "# Define the mapping\n",
    "state_to_code = {\n",
    "    'Napoli': 'NA',\n",
    "    # Add other mappings\n",
    "}\n",
    "\n",
    "# Replace null 'State Code' with mapped abbreviations\n",
    "customer['State Code'] = customer.apply(\n",
    "    lambda row: state_to_code.get(row['State'], row['State Code']) if pd.isnull(row['State Code']) else row['State Code'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step 2: Ensure there are no missing values in critical columns\n",
    "customer = customer.dropna(subset=['CustomerKey', 'Name', 'State Code', 'Country'])  # Modify as needed\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Birthday' column to datetime format if it's not already\n",
    "customer['Birthday'] = pd.to_datetime(customer['Birthday'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Assuming 'Birthday' column is in 'MM-DD-YYYY' format\n",
    "def calculate_age(birthdate):\n",
    "  # Check if birthdate is already a Timestamp object\n",
    "  if isinstance(birthdate, pd.Timestamp):\n",
    "    birthdate_obj = birthdate\n",
    "  else:\n",
    "    try:\n",
    "      birthdate_obj = datetime.strptime(birthdate, '%m-%d-%Y')\n",
    "    except ValueError:\n",
    "      return None\n",
    "  today = datetime.today()\n",
    "  age = today.year - birthdate_obj.year - ((today.month, today.day) < (birthdate_obj.month, birthdate_obj.day))\n",
    "  return age\n",
    "\n",
    "customer['Age'] = customer['Birthday'].apply(calculate_age)\n",
    "\n",
    "\n",
    "# Convert 'Birthday' column to datetime format if it's not already\n",
    "#customer['Birthday'] = pd.to_datetime(customer['Birthday'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Connect to the database\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"3odVFo6TfLUYgWX.root\",\n",
    "    password=\"k3MbqRTW3UQ601wG\",\n",
    "    database=\"dataspark\"\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Define the SQL Insert query\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO customer (CustomerKey, Gender, Name, City, StateCode, State, ZipCode, Country, Continent, Birthday,Age)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Batch insert function\n",
    "def batch_insert(cursor, connection, insert_query, data, batch_size=50):\n",
    "    try:\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch = data[i:i + batch_size]\n",
    "            cursor.executemany(insert_query, batch)\n",
    "            connection.commit()  # Commit after each batch\n",
    "        print(f\"{len(data)} records inserted successfully in batches of {batch_size}.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error inserting data in batches: {err}\")\n",
    "        connection.rollback()\n",
    "\n",
    "# Prepare data for batch insertion\n",
    "insert_data = [ (\n",
    "            row['CustomerKey'],\n",
    "            row['Gender'],\n",
    "            row['Name'],\n",
    "            row['City'],\n",
    "            row['State Code'],  # Ensure the column names match\n",
    "            row['State'],\n",
    "            row['Zip Code'],    # Ensure the column names match\n",
    "            row['Country'],\n",
    "            row['Continent'],\n",
    "            row['Birthday'].strftime('%Y-%m-%d') if pd.notna(row['Birthday']) else None,  # Convert to 'YYYY-MM-DD' format,\n",
    "            row['Age']\n",
    "        )\n",
    "    for _, row in customer.iterrows()\n",
    "]\n",
    "\n",
    "# Insert data into the table\n",
    "batch_insert(cursor, connection, insert_query, insert_data)\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Number</th>\n",
       "      <th>Line Item</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Delivery Date</th>\n",
       "      <th>CustomerKey</th>\n",
       "      <th>StoreKey</th>\n",
       "      <th>ProductKey</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Currency Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>366000</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265598</td>\n",
       "      <td>10</td>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366001</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>1/13/2016</td>\n",
       "      <td>1269051</td>\n",
       "      <td>0</td>\n",
       "      <td>1048</td>\n",
       "      <td>2</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>366001</td>\n",
       "      <td>2</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>1/13/2016</td>\n",
       "      <td>1269051</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366002</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>1/12/2016</td>\n",
       "      <td>266019</td>\n",
       "      <td>0</td>\n",
       "      <td>1106</td>\n",
       "      <td>7</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366002</td>\n",
       "      <td>2</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>1/12/2016</td>\n",
       "      <td>266019</td>\n",
       "      <td>0</td>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order Number  Line Item Order Date Delivery Date  CustomerKey  StoreKey  \\\n",
       "0        366000          1   1/1/2016           NaN       265598        10   \n",
       "1        366001          1   1/1/2016     1/13/2016      1269051         0   \n",
       "2        366001          2   1/1/2016     1/13/2016      1269051         0   \n",
       "3        366002          1   1/1/2016     1/12/2016       266019         0   \n",
       "4        366002          2   1/1/2016     1/12/2016       266019         0   \n",
       "\n",
       "   ProductKey  Quantity Currency Code  \n",
       "0        1304         1           CAD  \n",
       "1        1048         2           USD  \n",
       "2        2007         1           USD  \n",
       "3        1106         7           CAD  \n",
       "4         373         1           CAD  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sale = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/Sales.csv', encoding='latin1')\n",
    "sale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Order Number     Line Item   CustomerKey      StoreKey    ProductKey  \\\n",
      "count  6.288400e+04  62884.000000  6.288400e+04  62884.000000  62884.000000   \n",
      "mean   1.430905e+06      2.164207  1.180797e+06     31.802144   1125.859344   \n",
      "std    4.532963e+05      1.365170  5.859634e+05     22.978188    709.244010   \n",
      "min    3.660000e+05      1.000000  3.010000e+02      0.000000      1.000000   \n",
      "25%    1.121017e+06      1.000000  6.808580e+05      8.000000    437.000000   \n",
      "50%    1.498016e+06      2.000000  1.261200e+06     37.000000   1358.000000   \n",
      "75%    1.788010e+06      3.000000  1.686496e+06     53.000000   1650.000000   \n",
      "max    2.243032e+06      7.000000  2.099937e+06     66.000000   2517.000000   \n",
      "\n",
      "           Quantity  \n",
      "count  62884.000000  \n",
      "mean       3.144790  \n",
      "std        2.256371  \n",
      "min        1.000000  \n",
      "25%        1.000000  \n",
      "50%        2.000000  \n",
      "75%        4.000000  \n",
      "max       10.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62884 entries, 0 to 62883\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Order Number   62884 non-null  int64 \n",
      " 1   Line Item      62884 non-null  int64 \n",
      " 2   Order Date     62884 non-null  object\n",
      " 3   Delivery Date  13165 non-null  object\n",
      " 4   CustomerKey    62884 non-null  int64 \n",
      " 5   StoreKey       62884 non-null  int64 \n",
      " 6   ProductKey     62884 non-null  int64 \n",
      " 7   Quantity       62884 non-null  int64 \n",
      " 8   Currency Code  62884 non-null  object\n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 4.3+ MB\n",
      "None\n",
      "Order Number         0\n",
      "Line Item            0\n",
      "Order Date           0\n",
      "Delivery Date    49719\n",
      "CustomerKey          0\n",
      "StoreKey             0\n",
      "ProductKey           0\n",
      "Quantity             0\n",
      "Currency Code        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sale.describe())\n",
    "print(sale.info())\n",
    "print(sale.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import mysql.connector\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "  host = \"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "  port = 4000,\n",
    "  user = \"3odVFo6TfLUYgWX.root\",\n",
    "  password = \"k3MbqRTW3UQ601wG\",\n",
    "  database = \"dataspark\" \n",
    "  \n",
    ")\n",
    "cursor = connection.cursor(buffered=True)\n",
    "\n",
    "\n",
    "# Step 1: Create the table to match the columns of the 'sale' DataFrame\n",
    "# Database connection\n",
    "\n",
    "# SQL query to create a table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sale (\n",
    "    OrderNumber INT,\n",
    "    LineItem INT,\n",
    "    OrderDate DATE,\n",
    "    DeliveryDate DATE,\n",
    "    CustomerKey INT,\n",
    "    StoreKey INT,\n",
    "    ProductKey INT,\n",
    "    Quantity INT,\n",
    "    CurrencyCode VARCHAR(10)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    # Execute the query\n",
    "    cursor.execute(create_table_query)\n",
    "    print(\"Table created successfully.\")\n",
    "    \n",
    "    # Commit changes (optional for DDL operations like CREATE TABLE)\n",
    "    connection.commit()\n",
    "    \n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database successfully.\n",
      "Table 'cust' dropped successfully.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Step 1: Connect to the database\n",
    "try:\n",
    "    connection = mysql.connector.connect(\n",
    "  host = \"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "  port = 4000,\n",
    "  user = \"3odVFo6TfLUYgWX.root\",\n",
    "  password = \"k3MbqRTW3UQ601wG\",\n",
    "  database = \"dataspark\" \n",
    "  )\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    print(\"Connected to the database successfully.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Drop the table\n",
    "drop_table_query = \"DROP TABLE IF EXISTS customer;\"  # Replace 'sale' with your table name\n",
    "\n",
    "try:\n",
    "    cursor.execute(drop_table_query)\n",
    "    connection.commit()  # Not strictly required for DROP TABLE but good practice\n",
    "    print(\"Table 'customer' dropped successfully.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error dropping table: {err}\")\n",
    "finally:\n",
    "    # Step 3: Close the connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62884 records inserted successfully in batches of 50.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"3odVFo6TfLUYgWX.root\",\n",
    "    password=\"k3MbqRTW3UQ601wG\",\n",
    "    database=\"dataspark\"\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Load the CSV file\n",
    "sale = pd.read_csv(\n",
    "    'f:/project2/DataSet-20240917T082626Z-001/DataSet/Sales.csv',\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "# Convert date columns to datetime\n",
    "sale['Order Date'] = pd.to_datetime(sale['Order Date'], format='%m/%d/%Y', errors='coerce')\n",
    "sale['Delivery Date'] = pd.to_datetime(sale['Delivery Date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Define the SQL Insert query\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO sale (\n",
    "    OrderNumber, LineItem, OrderDate, DeliveryDate, CustomerKey, StoreKey, ProductKey, Quantity, CurrencyCode\n",
    ") VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Batch insert function\n",
    "def batch_insert(cursor, connection, insert_query, data, batch_size=50):\n",
    "    try:\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch = data[i:i + batch_size]\n",
    "            cursor.executemany(insert_query, batch)\n",
    "            connection.commit()  # Commit after each batch\n",
    "        print(f\"{len(data)} records inserted successfully in batches of {batch_size}.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error inserting data in batches: {err}\")\n",
    "        connection.rollback()\n",
    "\n",
    "# Prepare data for batch insertion\n",
    "insert_data = [\n",
    "    (\n",
    "        row['Order Number'],\n",
    "        row['Line Item'],\n",
    "        row['Order Date'].strftime('%Y-%m-%d') if pd.notnull(row['Order Date']) else None,\n",
    "        row['Delivery Date'].strftime('%Y-%m-%d') if pd.notnull(row['Delivery Date']) else None,\n",
    "        row['CustomerKey'],\n",
    "        row['StoreKey'],\n",
    "        row['ProductKey'],\n",
    "        row['Quantity'],\n",
    "        row['Currency Code']\n",
    "    )\n",
    "    for _, row in sale.iterrows()\n",
    "]\n",
    "\n",
    "# Insert data into the table\n",
    "batch_insert(cursor, connection, insert_query, insert_data)\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductKey                         Product Name    Brand   Color  \\\n",
      "0           1  Contoso 512MB MP3 Player E51 Silver  Contoso  Silver   \n",
      "1           2    Contoso 512MB MP3 Player E51 Blue  Contoso    Blue   \n",
      "2           3     Contoso 1G MP3 Player E100 White  Contoso   White   \n",
      "3           4    Contoso 2G MP3 Player E200 Silver  Contoso  Silver   \n",
      "4           5       Contoso 2G MP3 Player E200 Red  Contoso     Red   \n",
      "\n",
      "  Unit Cost USD Unit Price USD  SubcategoryKey Subcategory  CategoryKey  \\\n",
      "0        $6.62         $12.99              101     MP4&MP3            1   \n",
      "1        $6.62         $12.99              101     MP4&MP3            1   \n",
      "2        $7.40         $14.52              101     MP4&MP3            1   \n",
      "3       $11.00         $21.57              101     MP4&MP3            1   \n",
      "4       $11.00         $21.57              101     MP4&MP3            1   \n",
      "\n",
      "  Category  \n",
      "0    Audio  \n",
      "1    Audio  \n",
      "2    Audio  \n",
      "3    Audio  \n",
      "4    Audio  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2517, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "product = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/products.csv', encoding='latin1')\n",
    "print(product.head())\n",
    "product.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ProductKey  SubcategoryKey  CategoryKey\n",
      "count  2517.000000     2517.000000  2517.000000\n",
      "mean   1259.000000      491.810091     4.878824\n",
      "std     726.739637      229.887134     2.299170\n",
      "min       1.000000      101.000000     1.000000\n",
      "25%     630.000000      305.000000     3.000000\n",
      "50%    1259.000000      406.000000     4.000000\n",
      "75%    1888.000000      801.000000     8.000000\n",
      "max    2517.000000      808.000000     8.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2517 entries, 0 to 2516\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   ProductKey      2517 non-null   int64 \n",
      " 1   Product Name    2517 non-null   object\n",
      " 2   Brand           2517 non-null   object\n",
      " 3   Color           2517 non-null   object\n",
      " 4   Unit Cost USD   2517 non-null   object\n",
      " 5   Unit Price USD  2517 non-null   object\n",
      " 6   SubcategoryKey  2517 non-null   int64 \n",
      " 7   Subcategory     2517 non-null   object\n",
      " 8   CategoryKey     2517 non-null   int64 \n",
      " 9   Category        2517 non-null   object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 196.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(product.describe())\n",
    "print(product.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ProductKey, Product Name, Brand, Color, Unit Cost USD, Unit Price USD, SubcategoryKey, Subcategory, CategoryKey, Category]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Duplicate check in the Cutomerkey field\n",
    "\n",
    "duplicate_customer_product = product[product.duplicated(subset=['ProductKey'], keep=False)]\n",
    "print(duplicate_customer_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductKey        0\n",
       "Product Name      0\n",
       "Brand             0\n",
       "Color             0\n",
       "Unit Cost USD     0\n",
       "Unit Price USD    0\n",
       "SubcategoryKey    0\n",
       "Subcategory       0\n",
       "CategoryKey       0\n",
       "Category          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Null value any column\n",
    "product.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductKey                         Product Name    Brand   Color  \\\n",
      "0           1  Contoso 512MB MP3 Player E51 Silver  Contoso  Silver   \n",
      "1           2    Contoso 512MB MP3 Player E51 Blue  Contoso    Blue   \n",
      "2           3     Contoso 1G MP3 Player E100 White  Contoso   White   \n",
      "3           4    Contoso 2G MP3 Player E200 Silver  Contoso  Silver   \n",
      "4           5       Contoso 2G MP3 Player E200 Red  Contoso     Red   \n",
      "\n",
      "   Unit Cost USD  Unit Price USD  SubcategoryKey Subcategory  CategoryKey  \\\n",
      "0           6.62           12.99             101     MP4&MP3            1   \n",
      "1           6.62           12.99             101     MP4&MP3            1   \n",
      "2           7.40           14.52             101     MP4&MP3            1   \n",
      "3          11.00           21.57             101     MP4&MP3            1   \n",
      "4          11.00           21.57             101     MP4&MP3            1   \n",
      "\n",
      "  Category  \n",
      "0    Audio  \n",
      "1    Audio  \n",
      "2    Audio  \n",
      "3    Audio  \n",
      "4    Audio  \n"
     ]
    }
   ],
   "source": [
    "# Clean and convert 'Unit Cost USD' and 'Unit Price USD' columns to numeric\n",
    "for col in ['Unit Cost USD', 'Unit Price USD']:\n",
    "    product[col] = (\n",
    "        product[col].astype(str)  # Ensure string type\n",
    "        .str.replace('$', '', regex=False)  # Remove '$' symbol\n",
    "        .str.strip()  # Remove extra spaces\n",
    "        .apply(pd.to_numeric, errors='coerce')  # Convert to numeric, coercing errors to NaN\n",
    "        .fillna(0)  # Replace NaN with 0\n",
    "    )\n",
    "\n",
    "# Display the first few rows to verify changes\n",
    "print(product.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2517 record(s) inserted.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "product = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/products.csv', encoding='latin1')\n",
    "\n",
    "# Clean and convert 'Unit Cost USD' and 'Unit Price USD' columns to numeric\n",
    "for col in ['Unit Cost USD', 'Unit Price USD']:\n",
    "    product[col] = (\n",
    "        product[col].astype(str)  # Ensure string type\n",
    "        .str.replace('$', '', regex=False)  # Remove '$' symbol\n",
    "        .str.strip()  # Remove extra spaces\n",
    "        .apply(pd.to_numeric, errors='coerce')  # Convert to numeric, coercing errors to NaN\n",
    "        .fillna(0)  # Replace NaN with 0\n",
    "    )\n",
    "\n",
    "\n",
    "# Drop rows with missing critical values\n",
    "product = product.dropna(subset=['ProductKey', 'Product Name', 'Unit Cost USD', 'Unit Price USD'])\n",
    "\n",
    "# Connect to the database\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"3odVFo6TfLUYgWX.root\",\n",
    "    password=\"k3MbqRTW3UQ601wG\",\n",
    "    database=\"dataspark\"\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Step 1: Create the table if not exists\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS product (\n",
    "    ProductKey INT,\n",
    "    ProductName VARCHAR(255),\n",
    "    Brand VARCHAR(255),\n",
    "    Color VARCHAR(50),\n",
    "    UnitCostUSD FLOAT,\n",
    "    UnitPriceUSD FLOAT,\n",
    "    SubcategoryKey INT,\n",
    "    Subcategory VARCHAR(255),\n",
    "    CategoryKey INT,\n",
    "    Category VARCHAR(255)\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Step 2: Insert data into the MySQL table\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO product (ProductKey, ProductName, Brand, Color, UnitCostUSD, UnitPriceUSD, SubcategoryKey, Subcategory, CategoryKey, Category)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "try:\n",
    "    # Prepare a list of tuples for insertion\n",
    "    values = [\n",
    "        (\n",
    "            row['ProductKey'],\n",
    "            row['Product Name'],\n",
    "            row['Brand'],\n",
    "            row['Color'],\n",
    "            row['Unit Cost USD'],\n",
    "            row['Unit Price USD'],\n",
    "            row['SubcategoryKey'],\n",
    "            row['Subcategory'],\n",
    "            row['CategoryKey'],\n",
    "            row['Category']\n",
    "        )\n",
    "        for _, row in product.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Use executemany for bulk insertion\n",
    "    cursor.executemany(insert_query, values)\n",
    "\n",
    "    # Commit the transaction\n",
    "    connection.commit()\n",
    "    print(cursor.rowcount, \"record(s) inserted.\")\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error: {err}\")\n",
    "    connection.rollback()  # Rollback in case of error\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StoreKey    Country                         State  Square Meters  Open Date\n",
      "0         1  Australia  Australian Capital Territory          595.0   1/1/2008\n",
      "1         2  Australia            Northern Territory          665.0  1/12/2008\n",
      "2         3  Australia               South Australia         2000.0   1/7/2012\n",
      "3         4  Australia                      Tasmania         2000.0   1/1/2010\n",
      "4         5  Australia                      Victoria         2000.0  12/9/2015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67, 5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "store = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/stores.csv', encoding='latin1')\n",
    "print(store.head())\n",
    "store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 record(s) inserted.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "store = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/stores.csv', encoding='latin1')\n",
    "\n",
    "# Ensure the 'Open Date' column is in a valid datetime format\n",
    "store['Open Date'] = pd.to_datetime(store['Open Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Ensure there are no missing values in the DataFrame\n",
    "store = store.dropna()  # Remove rows with NaN values\n",
    "\n",
    "# Connect to the database\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"3odVFo6TfLUYgWX.root\",\n",
    "    password=\"k3MbqRTW3UQ601wG\",\n",
    "    database=\"dataspark\"\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create the table for storing the data\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS store (\n",
    "    StoreKey INT PRIMARY KEY,\n",
    "    Country VARCHAR(255),\n",
    "    State VARCHAR(255),\n",
    "    SquareMeters FLOAT,\n",
    "    OpenDate DATE\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Insert data from the DataFrame into the table\n",
    "for index, row in store.iterrows():\n",
    "    sql = \"INSERT INTO store (StoreKey, Country, State, SquareMeters, OpenDate) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    val = (row['StoreKey'], row['Country'], row['State'], row['Square Meters'], row['Open Date'].strftime('%Y-%m-%d'))\n",
    "    cursor.execute(sql, val)\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "print(cursor.rowcount, \"record(s) inserted.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date Currency  Exchange\n",
      "0  1/1/2015      USD    1.0000\n",
      "1  1/1/2015      CAD    1.1583\n",
      "2  1/1/2015      AUD    1.2214\n",
      "3  1/1/2015      EUR    0.8237\n",
      "4  1/1/2015      GBP    0.6415\n",
      "Date        0\n",
      "Currency    0\n",
      "Exchange    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11215, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "er = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/Exchange_Rates.csv', encoding='latin1')\n",
    "print(er.head())\n",
    "print(er.isnull().sum())\n",
    "er.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 record(s) inserted.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "er = pd.read_csv('f:/project2/DataSet-20240917T082626Z-001/DataSet/Exchange_Rates.csv', encoding='latin1')\n",
    "\n",
    "\n",
    "# Assuming the 'Date' column is in a valid datetime format\n",
    "er['Date'] = pd.to_datetime(er['Date'], format='%m/%d/%Y')  # Ensure it's a datetime object\n",
    "\n",
    "# Ensure there are no missing values in the DataFrame\n",
    "er = er.dropna()  # Remove rows with NaN values\n",
    "\n",
    "# Connect to the database\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"3odVFo6TfLUYgWX.root\",\n",
    "    password=\"k3MbqRTW3UQ601wG\",\n",
    "    database=\"dataspark\"\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create the table for storing the data\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS rate (\n",
    "    rdate date,  \n",
    "    Currency VARCHAR(255),\n",
    "    Rate FLOAT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "# Insert data from the DataFrame into the table\n",
    "for index, row in er.iterrows():\n",
    "    sql = \"INSERT INTO rate (rdate, Currency, Rate) VALUES (%s, %s, %s)\"\n",
    "    val = (row['Date'].strftime('%Y-%m-%d'), row['Currency'], row['Exchange'])  # Insert in 'YYYY-MM-DD' format\n",
    "    cursor.execute(sql, val)\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "\n",
    "print(cursor.rowcount, \"record(s) inserted.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
